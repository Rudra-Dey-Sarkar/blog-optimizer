# Blog Optimizer â€“ Full Stack Assignment

This repository contains a **full-stack blog optimization system**.

The project is implemented in  **three phases** :

1. **Article Scraping & CRUD APIs**
2. **Automated Article Optimization using Google Search + LLM**
3. **Frontend UI to view original and optimized articles**

## Live Links

* **Frontend:-** *(add once deployed)*
* **Video:-** *(optional public URL)*

## Local Setup Instructions

### 1. Clone the repository

`git clone https://github.com/Rudra-Dey-Sarkar/blog-optimizer.git`

` cd blog-optimizer`

### 2. Backend API Setup (Phase 1 + Phase 2)

`cd .\backend\api`

` npm install`

Create `.env`:-

`PORT=5000`

` DB_URLMONGO_UR=your_mongodb_connection_string`

### 2.1. Seed Initial Articles (Phase 1)

`node src/scripts/seed-articles.js`

This will:-

* Scrape the **5 oldest blogs**
* Store them as **published original articles**

Run API server:-

`npm run dev`

### 2.2. Worker Setup (Phase 2)

`cd .\backend\worker `

` npm install`

Create `.env`:-

`BACKEND_URL=http://localhost:5000`

` SERP_API_KEY=your_serpapi_key`

` LLM_API_KEY=your_llm_key`

Run worker:-

`npm run dev`

The worker will:-

* Fetch articles from API
* Search Google for references
* Scrape external articles
* Optimize content via LLM
* Publish optimized articles
* Gracefully handle failures with retries & rollback

### 3. Frontend Setup (Phase 3)

`cd .\frontend`

`npm install`

`npm run dev`

Frontend displays:-

* Original articles
* Optimized articles
* Reference sources

## Tech Stack

* **Backend:** Node.js, Express, MongoDB, Mongoose
* **Scraping:** Cheerio, JSDOM, Mozilla Readability
* **Search:** SerpAPI
* **LLM:** Groq
* **Frontend:** React
* **Infra:** Vercel

## Project Architecture

## Repository Structure

```

â””â”€â”€ ğŸ“blog-optimizer

    â””â”€â”€ ğŸ“backend

        â””â”€â”€ ğŸ“api

            â””â”€â”€ ğŸ“src

                â””â”€â”€ ğŸ“configs

                    â”œâ”€â”€ db.js

                â””â”€â”€ ğŸ“controllers

                    â”œâ”€â”€ articles.js

                â””â”€â”€ ğŸ“models

                    â”œâ”€â”€ articles.js

                â””â”€â”€ ğŸ“routes

                    â”œâ”€â”€ articles.js

                â””â”€â”€ ğŸ“scripts

                    â”œâ”€â”€ delete-articles.js

                    â”œâ”€â”€ seed-articles.js

                â””â”€â”€ ğŸ“services

                    â”œâ”€â”€ content-extractor.js

                â”œâ”€â”€ app.js

            â”œâ”€â”€ .env

            â”œâ”€â”€ .env.example

            â”œâ”€â”€ package-lock.json

            â”œâ”€â”€ package.json

        â””â”€â”€ ğŸ“worker

            â””â”€â”€ ğŸ“src

                â””â”€â”€ ğŸ“jobs

                    â”œâ”€â”€ optimize-article.js

                â””â”€â”€ ğŸ“services

                    â”œâ”€â”€ content-extractor.js

                    â”œâ”€â”€ google-search.js

                    â”œâ”€â”€ llm-service.js

                â”œâ”€â”€ worker.js

            â”œâ”€â”€ .env

            â”œâ”€â”€ .env.example

            â”œâ”€â”€ package-lock.json

            â”œâ”€â”€ package.json

    â””â”€â”€ ğŸ“frontend

    â”œâ”€â”€ .gitignore

    â””â”€â”€ README.md

```

## Reliability & Edge Cases

* **Retry logic for LLM failures (3 attempts)**
* **Automatic rollback** to published state if optimization fails
* Skips optimization when **no valid reference articles** are found
* Avoids self-referencing BeyondChats articles
* Handles Cloudflare / blocked sources gracefully
